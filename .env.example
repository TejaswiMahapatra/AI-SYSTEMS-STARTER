# ============================================================================
# AI Systems Starter - Environment Configuration
# ============================================================================
# DEFAULT: 100% Open Source (No API keys required!)
# OPTIONAL: Can switch to paid APIs for better quality
#
# Copy this file to .env: cp .env.example .env

# ============================================================================
# ENVIRONMENT
# ============================================================================
ENVIRONMENT=local

# ============================================================================
# LLM PROVIDER
# ============================================================================
# Options: ollama (default, free), openai, anthropic, mock
# 
# ollama (100% free, runs locally)
# openai or anthropic (costs money, better quality)
LLM_PROVIDER=ollama

# --- Open Source: Ollama (DEFAULT) ---
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
# Other options: mistral:7b, qwen2.5:7b, phi3:3.8b, llama3.1:70b

# --- Paid API: OpenAI (OPTIONAL) ---
OPENAI_API_KEY=  # Add key to use OpenAI
OPENAI_MODEL=gpt-4-turbo-preview

# --- Paid API: Anthropic (OPTIONAL) ---
ANTHROPIC_API_KEY=  # Add key to use Claude
ANTHROPIC_MODEL=claude-3-sonnet-20240229

# ============================================================================
# EMBEDDINGS PROVIDER
# ============================================================================
# Options: local (default, free), openai
#
# RECOMMENDED: local (sentence-transformers, free)
# OPTIONAL: openai (costs ~$0.0001 per 1K tokens)
EMBEDDING_PROVIDER=local

# --- Open Source: Local Embeddings (DEFAULT) ---
LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2
# Other options: all-mpnet-base-v2, multi-qa-MiniLM-L6-cos-v1

# --- Paid API: OpenAI Embeddings (OPTIONAL) ---
OPENAI_EMBEDDING_MODEL=text-embedding-3-small  # Or text-embedding-3-large

# ============================================================================
# VECTOR DATABASE
# ============================================================================
VECTOR_DB_PROVIDER=weaviate

# Weaviate (Open Source)
WEAVIATE_URL=http://localhost:8080

# ============================================================================
# DATABASE
# ============================================================================
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=ai_systems
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres

DATABASE_URL=postgresql://postgres:postgres@localhost:5432/ai_systems

# ============================================================================
# REDIS (Cache + Queue)
# ============================================================================
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_URL=redis://localhost:6379/0

# ============================================================================
# STORAGE (MinIO - S3 compatible, Open Source)
# ============================================================================
STORAGE_PROVIDER=minio

MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=ai-systems
MINIO_SECURE=false

# ============================================================================
# OBSERVABILITY
# ============================================================================
# LangSmith (Optional - free tier available)
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=ai-systems-starter

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json

# ============================================================================
# FRONTEND
# ============================================================================
NEXT_PUBLIC_API_URL=http://localhost:8000

# ============================================================================
# BACKEND
# ============================================================================
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
BACKEND_WORKERS=4

CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# ============================================================================
# WORKERS
# ============================================================================
WORKER_COUNT=2
WORKER_CONCURRENCY=4
WORKER_QUEUE_NAME=ingestion_queue

# ============================================================================
# FEATURE FLAGS
# ============================================================================
ENABLE_WEBSOCKETS=true
ENABLE_BACKGROUND_WORKERS=true
ENABLE_COST_TRACKING=true

# ============================================================================
# DEVELOPMENT
# ============================================================================
DEBUG=true
RELOAD=true
SEED_SAMPLE_DATA=true
SAMPLE_DATA_PATH=./examples/contracts

# ============================================================================
# QUICK START (100% FREE SETUP)
# ============================================================================
# 1. Install Ollama: https://ollama.ai
# 2. Pull model: ollama pull llama3.1:8b
# 3. Run: make init
# 4. Done! No API keys needed.
#
# UPGRADE TO PAID APIs (OPTIONAL):
# - Set LLM_PROVIDER=openai and add OPENAI_API_KEY
# - Set EMBEDDING_PROVIDER=openai
# - Better quality, costs money
#
# GPU RECOMMENDATIONS:
# - 8GB VRAM: llama3.1:8b, mistral:7b
# - 16GB VRAM: 13B models
# - 40GB+ VRAM: 70B models
# - No GPU: phi3:3.8b (slower but works!)
