# AI Systems Starter - Environment Configuration
# Copy this file to .env: cp .env.example .env

ENVIRONMENT=local

LLM_PROVIDER=ollama

OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b
#Other options: mistral:7b, qwen2.5:7b, phi3:3.8b, llama3.1:70b

OPENAI_API_KEY=  # Add key to use OpenAI
OPENAI_MODEL=gpt-4-turbo-preview

ANTHROPIC_API_KEY=  # Add key to use Claude
ANTHROPIC_MODEL=claude-3-sonnet-20240229

EMBEDDING_PROVIDER=local

LOCAL_EMBEDDING_MODEL=all-MiniLM-L6-v2
# Other options: all-mpnet-base-v2, multi-qa-MiniLM-L6-cos-v1

OPENAI_EMBEDDING_MODEL=text-embedding-3-small 

VECTOR_DB_PROVIDER=weaviate

WEAVIATE_URL=http://localhost:8080

POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=ai_systems
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
DATABASE_URL=postgresql://postgres:postgres@localhost:5432/ai_systems

REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_URL=redis://localhost:6379/0

STORAGE_PROVIDER=minio
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=minioadmin
MINIO_SECRET_KEY=minioadmin
MINIO_BUCKET=ai-systems
MINIO_SECURE=false

# LangSmith (Optional - free tier available)
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=ai-systems-starter

LOG_LEVEL=INFO
LOG_FORMAT=json

NEXT_PUBLIC_API_URL=http://localhost:8000

BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
BACKEND_WORKERS=4
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

WORKER_COUNT=2
WORKER_CONCURRENCY=4
WORKER_QUEUE_NAME=ingestion_queue

ENABLE_WEBSOCKETS=true
ENABLE_BACKGROUND_WORKERS=true
ENABLE_COST_TRACKING=true

DEBUG=true
RELOAD=true
SEED_SAMPLE_DATA=true
SAMPLE_DATA_PATH=./examples/contracts


# QUICK START 

# 1. Install Ollama: https://ollama.ai
# 2. Pull model: ollama pull llama3.1:8b
# 3. Run: make init
# 4. Done! No API keys needed.
#
# UPGRADE TO PAID APIs (OPTIONAL):
# - Set LLM_PROVIDER=openai and add OPENAI_API_KEY
# - Set EMBEDDING_PROVIDER=openai
# - Better quality, costs money
#
# GPU RECOMMENDATIONS:
# - 8GB VRAM: llama3.1:8b, mistral:7b
# - 16GB VRAM: 13B models
# - 40GB+ VRAM: 70B models
# - No GPU: phi3:3.8b (slower but works!)
